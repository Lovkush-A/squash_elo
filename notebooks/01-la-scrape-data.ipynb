{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.core.display import HTML\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/11892729/how-to-log-in-to-a-website-using-pythons-requests-module\n",
    "https://stackoverflow.com/questions/12203901/pandas-crashes-on-repeated-dataframe-reset-index/12204428"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"http://www.squashinfo.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tournament_data_from_url(url):\n",
    "    \"\"\"\n",
    "    url goes to list of tournaments\n",
    "    extract name, urls, etc. of each tournament in the list\n",
    "    returns list of lists\n",
    "    \"\"\"\n",
    "    html = requests.get(url).text\n",
    "    tables = BeautifulSoup(html, 'html.parser').find_all('table')\n",
    "    rows = tables[1].find_all('tr')[1:]\n",
    "    data = []\n",
    "\n",
    "    for row in rows:\n",
    "        entries = row.find_all('td')\n",
    "\n",
    "        tournament_type = entries[0].text\n",
    "        name = entries[1].text\n",
    "        tournament_url = base_url + entries[1].find_all('a', href=True)[0]['href']\n",
    "        location = entries[3].text\n",
    "        date = entries[4].text\n",
    "\n",
    "        data.append([tournament_type, name, location, date, tournament_url])\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def create_frame_of_tournaments():\n",
    "    columns = ['tournament_type', 'name', 'location', 'date', 'url']\n",
    "    df_tournaments = pd.DataFrame([], columns = columns)\n",
    "    \n",
    "    # men, range(1,142), type = 1\n",
    "    # women, range(1,79), type = 3\n",
    "    \n",
    "    for i in tqdm(range(1, 79)):\n",
    "        url = \"http://www.squashinfo.com/results?f_type=3&start=\" + str(i)\n",
    "        data = get_tournament_data_from_url(url)\n",
    "        df_tournaments = df_tournaments.append(pd.DataFrame(data, columns = columns))\n",
    "        \n",
    "    df_tournaments = df_tournaments.reset_index()\n",
    "    df_tournaments['matches_downloaded'] = False\n",
    "    df_tournaments.to_csv('tournaments_female.csv')\n",
    "    return df_tournaments\n",
    "\n",
    "\n",
    "def extract_information_from_row(row):\n",
    "    \"\"\"\n",
    "    input a row and extract information from it\n",
    "    determine whether it:\n",
    "    -determines which round of the tournament it is (final, semi-final, etc.)\n",
    "    -is an empty row\n",
    "    -details one of the matches in the tournament\n",
    "    \"\"\"\n",
    "    cols = row.find_all('td')\n",
    "    try:\n",
    "        row_class = cols[0]['class']\n",
    "    except KeyError:\n",
    "        return 'empty', None\n",
    "    \n",
    "    if row_class[0] == 'match_type':\n",
    "        text = cols[0].text.strip(':')\n",
    "        return 'round', text\n",
    "    elif row_class[0] == 'indv_col_1':\n",
    "        text = [cols[i].text.strip() for i in range(2)]\n",
    "        return 'match', text\n",
    "    else:\n",
    "        return 'empty', None\n",
    "\n",
    "\n",
    "def get_match_data_from_url(session, url):\n",
    "    html = session.get(url).text\n",
    "    tables = BeautifulSoup(html, 'html.parser').find_all('table')\n",
    "    rows = tables[0].find_all('tr')\n",
    "    \n",
    "    data = []\n",
    "    match_round = None\n",
    "    \n",
    "    for row in rows:\n",
    "        row_type, text = extract_information_from_row(row)\n",
    "        \n",
    "        if row_type == 'empty':\n",
    "            continue\n",
    "        elif row_type == 'round':\n",
    "            match_round = text\n",
    "        elif row_type == 'match':\n",
    "            players = text[0]\n",
    "            result = text[1]\n",
    "            data.append([match_round, players, result])\n",
    "    \n",
    "    return data\n",
    "\n",
    "        \n",
    "\n",
    "def create_frame_of_matches_from_tournament_frame(session, load_temp = False):\n",
    "    df_tournament = pd.read_csv('tournaments_female.csv', index_col = 0)\n",
    "#     dodgy = [2412]\n",
    "    dodgy = []\n",
    "    \n",
    "    columns = ['tournament_index', 'round', 'players', 'result']\n",
    "    columns_minus_tournament = ['round', 'players', 'result']\n",
    "    \n",
    "    if load_temp:\n",
    "        df_matches = pd.read_csv('temp_matches.csv', index_col = 0)\n",
    "    else:\n",
    "        df_matches = pd.DataFrame([], columns = columns)\n",
    "    \n",
    "    for index in tqdm(range(1558)):\n",
    "        if df_tournament.loc[index, 'matches_downloaded']:\n",
    "            continue\n",
    "\n",
    "        if index in dodgy:\n",
    "            continue\n",
    "        \n",
    "        url = df_tournament.loc[index, 'url']\n",
    "        print(f'{index}, {url}')\n",
    "        \n",
    "        try:\n",
    "            data = get_match_data_from_url(session, url)\n",
    "            df_data = pd.DataFrame(data, columns = columns_minus_tournament)\n",
    "            df_data['tournament_index'] = index\n",
    "            \n",
    "            df_matches = df_matches.append(df_data)\n",
    "            df_matches = df_matches.reset_index(drop=True)\n",
    "            df_matches.to_csv('temp_matches.csv')\n",
    "\n",
    "            df_tournament.loc[index, 'matches_downloaded'] = True\n",
    "            df_tournament.to_csv('tournaments_female.csv')\n",
    "        except IndexError:\n",
    "            print(index)\n",
    "            dodgy.append(index)\n",
    "\n",
    "    return df_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_frame_of_tournaments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('tournaments_female.csv', index_col = 0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.matches_downloaded]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "login_url = base_url+'/login'\n",
    "payload = {\n",
    "    'l_email': '', # manually fill in\n",
    "    'l_password': '' # manually fill in\n",
    "}\n",
    "\n",
    "with requests.Session() as s:\n",
    "    p = s.post(login_url, data=payload)\n",
    "    df_matches = create_frame_of_matches_from_tournament_frame(s, load_temp = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_temp = pd.read_csv('temp_matches.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_temp.to_csv('womens_matches_all.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing functions on individual urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "login_url = base_url+'/login'\n",
    "payload = {\n",
    "    'l_email': '', # manually fill in\n",
    "    'l_password': '' # manually fill in\n",
    "}\n",
    "\n",
    "with requests.Session() as s:\n",
    "    p = s.post(login_url, data=payload)\n",
    "#     print(p.text)\n",
    "    \n",
    "    url = df.loc[98, 'url']\n",
    "    print(url)\n",
    "#     url = 'http://www.squashinfo.com/events/7520-mens-british-national-championship-2018'\n",
    "    html = s.get(url).text\n",
    "    tables = BeautifulSoup(html, 'html.parser').find_all('table')\n",
    "#     rows = tables[0].find_all('tr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in rows:\n",
    "    row_type, text = extract_information_from_row(row)\n",
    "    print(f'{row_type}, {text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## troublesome links\n",
    "2412\t, 'http://www.squashinfo.com/events/1307-mens-international-tirolean-championship-1996'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
