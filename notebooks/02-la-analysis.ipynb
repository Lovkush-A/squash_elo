{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72ce745",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74e5199",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_processed = \"../data/processed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238fe97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = pd.read_csv(dir_processed+\"matches.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c72bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84ce4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_predicted_score(\n",
    "    rating1: float,\n",
    "    rating2: float\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Calculate the predicted score using ELO rating system\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    rating1, rating2: float\n",
    "        ELO ratings of two players\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The predicted score of a player with rating1 against\n",
    "        a player with rating2 using the ELO rating system\n",
    "    \"\"\"\n",
    "    return 1 / (1 + 10**((rating2 - rating1) / 400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a8ac0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_new_ratings(\n",
    "    rating_winner: float,\n",
    "    rating_loser: float,\n",
    "    predicted_score: float,\n",
    "    K: float = 32,\n",
    ") -> (float, float):\n",
    "    \"\"\"\n",
    "    Calculate new elo ratings.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    rating_winner, rating_loser: float\n",
    "        ELO ratings of the winner and loser, respectively.\n",
    "    predicted_score: float in range [0, 1]\n",
    "        The expected score of the winner of the match.\n",
    "    K: float, default 32\n",
    "        Constant that determines how much the ratings are adjusted.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    new_rating_winner, new_rating_loser: float\n",
    "        New ELO ratings\n",
    "    \"\"\"\n",
    "    delta_rating = K * (1 - predicted_score)\n",
    "\n",
    "    new_rating_winner = rating_winner + delta_rating\n",
    "    new_rating_loser = rating_loser - delta_rating\n",
    "\n",
    "    return new_rating_winner, new_rating_loser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d9d840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually test the above functions\n",
    "\n",
    "for delta in range(-500, 501, 50):\n",
    "    predicted_score = calculate_predicted_score(delta, 0)\n",
    "    new_rating_winner, new_rating_loser = calculate_new_ratings(\n",
    "        delta, 0, predicted_score\n",
    "    )\n",
    "    \n",
    "    print(f'Old winner rating: {delta:3}.')\n",
    "    print(f'Old loser rating: 0')\n",
    "    print(f'Predicted score: {predicted_score}')\n",
    "    print(f'New winner rating: {new_rating_winner}')\n",
    "    print(f'New loser rating: {new_rating_loser}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f90394",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_ratings(player_ratings, winner_name, loser_name):\n",
    "    \"\"\"\n",
    "    Update ratings based on a single new result.\n",
    "\n",
    "    If winner or loser is not already in the player_ratings\n",
    "    dictionary, then a fresh entry with a rating of 1500 is\n",
    "    created.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    player_ratings: Dict[str, float]\n",
    "        dictionary of player ratings\n",
    "    winner_name, loser_name: str,\n",
    "        name of winner and loser\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    player_ratings\n",
    "        updated player ratings\n",
    "    rating_winner_old\n",
    "    rating_winner_new\n",
    "    rating_loser_old\n",
    "    rating_loser_new\n",
    "    predicted_score\n",
    "    \"\"\"\n",
    "    if winner_name not in player_ratings:\n",
    "        player_ratings[winner_name] = 1500\n",
    "    rating_winner_old = player_ratings[winner_name]\n",
    "\n",
    "    if loser_name not in player_ratings:\n",
    "        player_ratings[loser_name] = 1500\n",
    "    rating_loser_old = player_ratings[loser_name]\n",
    "\n",
    "    predicted_score = calculate_predicted_score(rating_winner_old, rating_loser_old)\n",
    "\n",
    "    rating_winner_new, rating_loser_new = calculate_new_ratings(\n",
    "        rating_winner_old, rating_loser_old, predicted_score\n",
    "    )\n",
    "    \n",
    "    player_ratings[winner_name] = rating_winner_new\n",
    "    player_ratings[loser_name] = rating_loser_new\n",
    "\n",
    "    return (\n",
    "        player_ratings,\n",
    "        rating_winner_old,\n",
    "        rating_winner_new,\n",
    "        rating_loser_old,\n",
    "        rating_loser_new,\n",
    "        predicted_score,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33befe7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually test update_ratings\n",
    "\n",
    "test_ratings = {'a': 1000, 'b': 900}\n",
    "\n",
    "test_ratings, _, _, _, _, _ = update_ratings(test_ratings, 'a', 'b')\n",
    "test_ratings, _, _, _, _, _ = update_ratings(test_ratings, 'c', 'd')\n",
    "test_ratings, _, _, _, _, _ = update_ratings(test_ratings, 'd', 'c')\n",
    "\n",
    "test_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06bbfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_elo(matches: pd.DataFrame, player_ratings={}) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate elo ratings for all players and match history from\n",
    "    the matches input.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    matches: pd.DataFrame\n",
    "        dataframe of match history\n",
    "    player_ratings: Dict[str, float]\n",
    "        dictionary of players' elo ratings\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    player_ratings: Dict[str, float]\n",
    "        updated player_ratings\n",
    "    pd.DataFrame\n",
    "        copy of matches dataframe with new columns for:\n",
    "        * rating_winner_old\n",
    "        * rating_winner_new\n",
    "        * rating_loser_old\n",
    "        * rating_loser_new\n",
    "        * predicted_score\n",
    "    \"\"\"\n",
    "    ratings_winner_old = []\n",
    "    ratings_winner_new = []\n",
    "    ratings_loser_old = []\n",
    "    ratings_loser_new = []\n",
    "    predicted_scores = []\n",
    "\n",
    "    df = matches.copy()\n",
    "\n",
    "    for _, row in tqdm(df.iterrows()):\n",
    "        winner_name = row.winner_name\n",
    "        loser_name = row.loser_name\n",
    "\n",
    "        (\n",
    "            player_ratings,\n",
    "            rating_winner_old,\n",
    "            rating_winner_new,\n",
    "            rating_loser_old,\n",
    "            rating_loser_new,\n",
    "            predicted_score,\n",
    "        ) = update_ratings(player_ratings, winner_name, loser_name)\n",
    "        \n",
    "        ratings_winner_old.append(rating_winner_old)\n",
    "        ratings_winner_new.append(rating_winner_new)\n",
    "        ratings_loser_old.append(rating_loser_old)\n",
    "        ratings_loser_new.append(rating_loser_new)\n",
    "        predicted_scores.append(predicted_score)\n",
    "    \n",
    "    df['rating_winner_old'] = ratings_winner_old\n",
    "    df['rating_winner_new'] = ratings_winner_new\n",
    "    df['rating_loser_old'] = ratings_loser_old\n",
    "    df['rating_loser_new'] = ratings_loser_new\n",
    "    df['predicted_score'] = predicted_scores\n",
    "    \n",
    "    return player_ratings, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b05073",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_ratings, matches = calculate_elo(matches)\n",
    "matches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77065a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_player_history(df: pd.DataFrame, player: str) -> None:\n",
    "    \"\"\"\n",
    "    View all results of a player.\n",
    "    \n",
    "    Prints the following for all games that player played in:\n",
    "    * name of winner\n",
    "    * name of loser\n",
    "    * winners elo rating (before the match)\n",
    "    * losers elo rating (before the match)\n",
    "    * winners seed in the tournament\n",
    "    * losers seed in the tournament\n",
    "    * predicted score from elo ratings for the match\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df\n",
    "        dataframe of matches as outputted by calculate_elo\n",
    "    player: str\n",
    "        name of the player\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    indices = (df.winner_name == player) | (df.loser_name == player)\n",
    "    df_player = df[indices]\n",
    "    \n",
    "    for _,row in df_player.iterrows():\n",
    "        w = row.winner_name\n",
    "        wr = row.rating_winner_old\n",
    "        ws = row.winner_seed\n",
    "        l = row.loser_name\n",
    "        lr = row.rating_loser_old\n",
    "        ls = row.loser_seed\n",
    "        pred = row.predicted_score\n",
    "        print(f'{w[0:10]:10} beat {l[0:10]:10} {wr:.0f} vs {lr:.0f}   {ws:3} vs {ls:3}   {pred:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd50e44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_player_history(df, 'Ramy Ashour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6fc014",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_calibration(df_input: pd.DataFrame, N: int = 2) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Evaluate how well calibrated the ELO ratings are.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_input\n",
    "        Dataframe as outputted by calculate_elo\n",
    "    N: int\n",
    "        Number of times each bucket of size 0.1 is broken up.\n",
    "        See the index of the returned pd.Series for an example\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.Series\n",
    "        * index is predicted score, rounded to nearest 0.1/N. For\n",
    "          example, if N=2, then rounded to nearest 0.05, so index is\n",
    "          0.5, 0.55, 0.6,...,0.95, 1\n",
    "        * values are the average true score of matches whose predicted\n",
    "        score is in that bucket\n",
    "    \"\"\"\n",
    "    df = df_input.copy()\n",
    "\n",
    "    df[\"predicted_score_better_player\"] = df.predicted_score.apply(\n",
    "        lambda x: round(N * x, 1) / N if x > 0.5 else 1 - round(N * x, 1) / N\n",
    "    )\n",
    "\n",
    "    df[\"true_score_better_player\"] = df.predicted_score.apply(\n",
    "        lambda x: 1 if x > 0.5 else 0\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        df\n",
    "        .groupby(\"predicted_score_better_player\")\n",
    "        .agg({\"true_score_better_player\": [\"count\", \"mean\"]})\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7a732a",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_calibration(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
