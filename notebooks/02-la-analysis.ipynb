{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e01e4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36d35fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_processed = \"../data/processed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ecf32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = pd.read_csv(dir_processed+\"matches.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c600335b",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec51b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_expected_score(\n",
    "    rating1: float,\n",
    "    rating2: float\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Calculate the expected score using ELO rating system\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    rating1, rating2: float\n",
    "        ELO ratings of two players\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The expected score of a player with rating1 against\n",
    "        a player with rating2 using the ELO rating system\n",
    "    \"\"\"\n",
    "    return 1 / (1 + 10**((rating2 - rating1) / 400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852d4f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_new_ratings(\n",
    "    rating_winner: float,\n",
    "    rating_loser: float,\n",
    "    expected_score: float,\n",
    "    K: float = 32,\n",
    ") -> (float, float):\n",
    "    \"\"\"\n",
    "    Calculate new elo ratings.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    rating_winner, rating_loser: float\n",
    "        ELO ratings of the winner and loser, respectively.\n",
    "    expected_score: float in range [0, 1]\n",
    "        The expected score of the winner of the match.\n",
    "    K: float, default 32\n",
    "        Constant that determines how much the ratings are adjusted.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    new_rating_winner, new_rating_loser\n",
    "        New ELO ratings\n",
    "    \"\"\"\n",
    "    delta_rating = K * (1 - expected_score)\n",
    "\n",
    "    new_rating_winner = rating_winner + delta_rating\n",
    "    new_rating_loser = rating_loser - delta_rating\n",
    "\n",
    "    return new_rating_winner, new_rating_loser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55030749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually test the above functions\n",
    "\n",
    "for delta in range(-500, 501, 50):\n",
    "    expected_score = calculate_expected_score(delta, 0)\n",
    "    new_rating_winner, new_rating_loser = calculate_new_ratings(\n",
    "        delta, 0, expected_score\n",
    "    )\n",
    "    \n",
    "    print(f'Old winner rating: {delta:3}.')\n",
    "    print(f'Old loser rating: 0')\n",
    "    print(f'Expected score: {expected_score}')\n",
    "    print(f'New winner rating: {new_rating_winner}')\n",
    "    print(f'New loser rating: {new_rating_loser}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666993ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
